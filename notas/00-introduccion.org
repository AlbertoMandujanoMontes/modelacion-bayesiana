#+TITLE: EST-46115: Modelación Bayesiana
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Introducción~
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/00-introduccion.pdf
:END:
#+STARTUP: showall
#+PROPERTY: header-args:R :session intro :exports both :results output org :tangle ../rscripts/00-introduccion.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc latex

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2023.\\
*Objetivo*. Repasar notación que utilizaremos a lo largo del curso. Y a la vez, establecer la motivación de los temas que trataremos en la materia.\\
*Lecturas recomendas*: Notas del [[https://fundamentos-est-2021.netlify.app/][curso de fundamentos]] (2021) y sección 1 de citep:Gelman2020. 
#+END_NOTES

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#motivación][Motivación]]
- [[#notación][Notación]]
  - [[#definición-distribución-paramétrica][Definición [Distribución paramétrica]:]]
- [[#repaso-de-probabilidad][Repaso de probabilidad]]
  - [[#definición-espacio-de-probabilidad][~Definición~ [Espacio de Probabilidad]:]]
  - [[#definición-variable-aleatoria][~Definición~ [Variable aleatoria]:]]
  - [[#definición-función-de-acumulación][~Definición~ [Función de acumulación]:]]
  - [[#definición-función-de-densidad][~Definición~ [Función de densidad]:]]
  - [[#teorema-ley-de-los-grandes-números][~Teorema~ [Ley de los Grandes Números]:]]
  - [[#teorema-límite-central][~Teorema~ [Límite Central]:]]
- [[#repaso-inferencia][Repaso Inferencia]]
  - [[#regla-de-bayes][Regla de Bayes]]
  - [[#ejemplos][Ejemplos]]
- [[#repaso-inferencia][Repaso inferencia]]
  - [[#ejemplo][Ejemplo]]
  - [[#diferentes-previas-diferentes-posteriores][Diferentes previas, diferentes posteriores]]
  - [[#diferentes-datos-diferentes-posteriores][Diferentes datos, diferentes posteriores]]
  - [[#análisis-secuencial][Análisis secuencial]]
  - [[#tarea][Tarea]]
- [[#motivación][Motivación]]
  - [[#distinción-importante][Distinción importante]]
  - [[#por-qué-necesitamos-un-flujo-de-trabajo][¿Por qué necesitamos un flujo de trabajo?]]
  - [[#proceso-iterativo][Proceso iterativo]]
:END:

* Motivación



* Notación

Denotamos por $x$ una ~variable aleatoria~ y por $\mathbb{P}(\cdot)$ una ~función
de distribución~. Escribimos $x \sim \mathbb{P}$ para denotar que la variable
aleatoria $x$ tiene distribución $\mathbb{P}(\cdot)$. Denotamos por
$\mathbb{E}[\cdot]$ el ~valor esperado~ del argumento con respecto a la
distribución que estamos considerando. Durante el curso seremos explícitos en la
variable aleatoria y usaremos
\begin{align}
\mathbb{E}_x[\cdot] = \int_\mathcal{X} \cdot \, \pi(x) \, \text{d}x\,,
\end{align}
o bien, haremos énfasis en la distribución por medio de lo siguiente
\begin{align}
\mathbb{E}_\pi[\cdot] = \int_\mathcal{X} \cdot \, \pi(x) \, \text{d}x\,,
\end{align}
de acuerdo al contexto. 

# \medskip

#+BEGIN_NOTES
Nota que en las ecuaciones anteriores estamos considerando el término
$\pi(\cdot)$ como la ~función de densidad~ de la ~función de probabilidad~
$\mathbb{P}(\cdot)$.
#+END_NOTES

#+REVEAL: split
Nos será útil la siguiente notación para evaluar valores esperados
\begin{align}
\pi(f)  := \mathbb{E}_\pi[f(x)] = \int_\mathcal{X} f(x) \, \pi(x) \, \text{d}x\,,
\end{align}
pues será el ~objetivo general~ para los métodos que estudiaremos en el curso. 

#+REVEAL: split
Por ejemplo, utilizaremos la noción de ~aproximar integrales~ por medio de algún
procedimiento de muestreo de tal forma que esperaremos construir un estimación
$\hat \pi (f)$ con cierto grado de refinamiento. Por ejemplo, veremos el ~método
Monte Carlo~ que utiliza una colección de $N$ simulaciones para aproximar la
integral anterior. Esto lo denotaremos por
\begin{align}
\hat \pi_{N}^{\cdot} (f) \approx \pi(f)\,. 
\end{align}

#+REVEAL: split
En general, nos interesa, y esperamos que, podamos: 
1. Mejorar nuestra estimación con mas simulaciones
   \begin{align}
   \lim_{N \rightarrow \infty} \hat \pi_{N}^{\cdot} (f) = \pi(f)\,
   \end{align}
2. Cuantificar la incertidumbre en nuestra aproximación por medio de alguna distribución de probabilidad. Por ejemplo,
   \begin{align}
   \hat \pi_{N}^{\cdot} (f) \sim \mathsf{N}\left( \pi(f), \frac{\mathbb{V}(f)}{N} \right)\,.
   \end{align}
\newpage
*** ~Definición~ [Distribución paramétrica]: 

Decimos que una función de distribución es ~paramétrica~ si se puede identificar completamente la distribución con respecto a un ~vector de parámetros~ $\theta \in \mathbb{R}^p$. Esto lo denotamos de la siguiente manera
\begin{align}
\pi_\theta(x) \qquad \text{ ó } \qquad \pi(x ; \theta)\,,
\end{align}
y si  $\theta \neq\theta'$ entonces $\pi_\theta(x) \neq \pi_{\theta'}(x)$ para cualquier $x$ en el ~soporte~.

* Repaso de probabilidad

Consideraremos como requisitos el contenido de ~Cálculo de Probabilidades II~ y
~Álgebra Lineal~ (o equivalentes). En particular lo que requerimos como base es lo siguiente.

*** *~Definición~ [Espacio de Probabilidad]*:
Un espacio de probabilidad está definido por la terna $(\Omega, \mathcal{X}, \mathbb{P})$:
1. El espacio muestral, $\Omega$ (elementos). 
2. El espacio de eventos medibles, $\mathcal{X}$ (subconjuntos). 
3. La medida de probabilidad, $\mathbb{P}: \mathcal{X} \rightarrow [0, 1]$. 

*** *~Definición~ [Variable aleatoria]*:
Una variable aleatoria es una función $X:
\mathcal{X} \rightarrow \mathbb{R}$ con la propiedad de que las pre-imágenes
bajo $X$ son eventos medibles. Es decir,
\begin{align}
\{w \in \mathcal{X} : X(w) \leq x \} \in \mathcal{X} \qquad \forall x \in \mathbb{R}. 
\end{align}
   
*** *~Definición~ [Función de acumulación]*:
Para toda variable aleatoria $X$ tenemos una función de acumulación
$\mathbb{P}_{_X}: \mathbb{R} \rightarrow [0, 1]$ dada por
\begin{align}
\mathbb{P}_{_X}(x) = \mathbb{P} \big( \{w \in \mathcal{X} : X(w) \leq x\} \big)\,.
\end{align}
Esto usualmente lo escribimos como $\mathbb{P}_{_X}(x) = \mathbb{P}\{X \leq x\}$. 

*** *~Definición~ [Función de densidad]*:
Una variable aleatoria es continua si su función de acumulación es ~absolutamente
continua~ y puede ser expresada por medio de
\begin{align}
\mathbb{P}_{_X} (x) = \int_{- \infty}^x \pi (s) \, \text{d}s\,, 
\end{align}
donde la anti-derivada $\pi:\mathbb{R} \rightarrow [0, \infty)$ se llama la ~función de
densidad~ de la variable aleatoria $X$. 

#+REVEAL: split
Las propiedades generales de las distribuciones de probabilidad se pueden
especificar por medio de su centralidad (localización), su dispersión, su rango
de valores, su simetría y el comportamiento de valores extremos.

#+REVEAL: split
En general esto lo podemos extraer de los momentos
\begin{align}
\mathbb{E}(X^p) = \int_{\mathbb{R}}^{} x^p \, \pi(x) \, \text{d}x\,,
\end{align}
o los momentos centrales. Por ejemplo: media y varianza. 

#+REVEAL: split
Uno de los resultados que espero recuerden bien de sus cursos anteriores es el
de la ~Ley de los Grandes Números~. La cual podemos enunciar como:

*** *~Teorema~ [Ley de los Grandes Números]*:
Sea $X_1, X_2, \ldots$ una colección de variables aleatorias independientes e
idénticamente distribuidas ($\mathsf{iid}$) y sea $\bar X_n$ el promedio de un
subconjunto de $n$.  Si denotamos por $\mu$ el valor promedio de $X_i$
dentro de esa colección, entonces tenemos que
\begin{align}
\bar X_n  \rightarrow \mu \quad (\text{casi seguramente})\,.
\end{align}

*** *~Teorema~ [Límite Central]*:
Sea $X_1, \ldots, X_n$ una colección de $n$ variables aleatorias $\mathsf{iid}$ con $\mathbb{E}[X_i] = \mu$ y $\mathbb{V}[X_i] = \sigma^2 < \infty$. Entonces
\begin{align}
\bar X_n \sim \mathsf{N}\left( \mu, \frac{\sigma^2}{n} \right)\,,
\end{align}
para $n$ suficientemente grande.

* Repaso Inferencia 

#+BEGIN_NOTES
Repaso de inferencia bajo un enfoque frecuentista. 
#+END_NOTES


#+REVEAL: split

#+REVEAL: split
** Regla de Bayes

La ~regla de Bayes~ utiliza la definición de probabilidad condicional para hacer inferencia a través de 
\begin{align}
\pi(A|B) = \frac{\pi(B|A) \pi(A)}{\pi(B)}\,.
\end{align}
#+REVEAL: split

#+DOWNLOADED: screenshot @ 2022-01-21 20:44:26
#+caption: Tomado de cite:Kruschke2014 .
#+attr_html: :width 1200 :align center
[[file:images/20220121-204426_screenshot.png]]

** Ejemplos

#+ATTR_REVEAL: :frag (appear)
- Verosimilitud: $x |\theta \sim \mathsf{Binomial}(n, \theta)$ + Previa: $\theta \sim \mathsf{Beta}(\alpha, \beta)$ = Posterior: ?
- Verosimilitud: $x |\theta \sim \mathsf{Uniforme}(0, \theta)$ + Previa: $\theta \sim \mathsf{Pareto}(\alpha, \theta_0)$ = Posterior: ?

* Repaso inferencia

#+BEGIN_NOTES
Repaso de inferencia bajo un enfoque bayesiano.
#+END_NOTES

** Ejemplo

Este ejemplo fue tomado de citep:Dogucu2021.

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)
  set.seed(108727)
  
  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 4)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src


** Diferentes previas, diferentes posteriores

#+begin_src R :exports none :results none
  ## Diferentes previas, diferentes posteriores --------------------
#+end_src

#+begin_src R :exports code 
  modelo_beta <- function(params, n = 5000){
    rbeta(n, params$alpha, params$beta)
  }
#+end_src


#+REVEAL: split
#+begin_src R :exports code 
    escenarios <-
      tibble(analista = fct_inorder(c("Ignorante", "Indiferente",
                                      "Feminista", "Ingenuo")),
             alpha = c(1, .5, 5, 14),
             beta  = c(1, .5, 11, 1)) |>
      nest(params.previa = c(alpha, beta)) |>
      mutate(muestras.previa = map(params.previa, modelo_beta))
#+end_src

#+RESULTS:
#+begin_src org
#+end_src

#+HEADER: :width 1200 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas.jpeg :exports results :results output graphics file
  escenarios |>
    unnest(muestras.previa) |>
    ggplot(aes(muestras.previa)) +
    geom_histogram(binwidth = .05) +
    facet_wrap(.~analista, scales = "free_y", ncol = 4) +
    xlab("Proporción de películas") + sin_lineas
#+end_src
#+caption: Muestras de $\theta \sim \mathsf{Previa}$ . 
#+RESULTS:
[[file:../images/peliculas.jpeg]]


#+REVEAL: split
#+HEADER: :width 1200 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas_predictiva.jpeg :exports results :results output graphics file
  escenarios |>
    unnest(muestras.previa) |>
    mutate(peliculas = map_dbl(muestras.previa,
                           function(theta) rbinom(1, 33, theta))) |>
    ggplot(aes(peliculas)) +
    geom_histogram(binwidth = 3) +
    facet_wrap(.~analista, scales = "free_y", ncol = 4) + sin_lineas
#+end_src
#+caption: Distribución predictiva previa
#+RESULTS:
[[file:../images/peliculas_predictiva.jpeg]]

#+REVEAL: split
#+begin_src R  :exports none :results none
  library(bayesrules)
  set.seed(108727)
  data <- bechdel |>
    sample_n(20)
#+end_src

#+begin_src R :exports none :results none
  data <- data |>
    group_by(binary) |>
    tally() |>
    pivot_wider(names_from = binary,
                values_from = n) 
#+end_src

#+begin_src R :exports code
  update_rule <- function(params){
    tibble(alpha = params$alpha + data$PASS,
           beta  = params$beta  + data$FAIL)
  }
  escenarios <- escenarios |>
    mutate(params.posterior = map(params.previa, update_rule),
           muestras.posterior = map(params.posterior, modelo_beta))
#+end_src

#+RESULTS:
#+begin_src org
#+end_src

#+HEADER: :width 1400 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas_posterior.jpeg :exports results :results output graphics file
  escenarios |>
    pivot_longer(cols = c(muestras.previa, muestras.posterior)) |>
    unnest(value) |>
    ggplot(aes(value, group = name, fill = name)) +
    geom_histogram(position = "identity", alpha = .7) +
    facet_wrap(.~analista, ncol = 4, scales = "free_y") +
    geom_vline(xintercept = data$PASS / 20, lty = 2) +
    xlab("Proporción de películas") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/peliculas_posterior.jpeg]]

#+REVEAL: split
#+HEADER: :width 1200 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas-predictiva-posterior.jpeg :exports results :results output graphics file
  escenarios |>
   unnest(muestras.posterior) |>
      mutate(peliculas = map_dbl(muestras.posterior,
                             function(theta) rbinom(1, 33, theta))) |>
      ggplot(aes(peliculas)) +
      geom_histogram(binwidth = 3) +
      facet_wrap(.~analista, scales = "free_y", ncol = 4) + sin_lineas
#+end_src
#+caption: Predictiva posterior. 
#+RESULTS:
[[file:../images/peliculas-predictiva-posterior.jpeg]]

** Diferentes datos, diferentes posteriores


#+begin_src R :exports none :results none
  ## Diferentes datos, diferentes posteriores -------------------
#+end_src

#+begin_src R  :exports none :results none
  extrae_datos <- function(n){
    bechdel |>
      sample_n(n) |>
      group_by(binary) |>
      tally() |>
      pivot_wider(names_from = binary,
                  values_from = n)
  }

  update_rule <- function(data){
      tibble(alpha = params.fem$alpha + data$PASS,
             beta  = params.fem$beta  + data$FAIL)
  }

  params.fem <- list(alpha = 5, beta = 11)

  escenarios <- tibble(id = seq(1, 4),
         n = c(5, 20, 100, 500),
         datos = map(n, extrae_datos))

  escenarios <- escenarios |>
    mutate(params.posterior = map(datos, update_rule),
           muestras.posterior = map(params.posterior, modelo_beta),
           muestras.previa    = list(modelo_beta(params.fem)))

#+end_src

#+RESULTS:
#+begin_src org
#+end_src

#+HEADER: :width 1200 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas_datos.jpeg :exports results :results output graphics file
  escenarios |>
     pivot_longer(cols = c(muestras.previa, muestras.posterior)) |>
     unnest(value) |>
     ggplot(aes(value, group = name, fill = name)) +
     geom_histogram(aes(y = ..density..), position = "identity", alpha = .7) +
     facet_wrap(.~n, ncol = 4) +
    xlab("Proporción de películas") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/peliculas_datos.jpeg]]

** Análisis secuencial 

#+HEADER: :width 1200 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas_historico.jpeg :exports results :results output graphics file
  bechdel |>
    group_by(year, binary) |>
    tally() |>
    pivot_wider(values_from = n,
                names_from = binary,
                values_fill = 0) |>
    mutate(rate = PASS/(PASS+FAIL)) |>
    ggplot(aes(year, rate)) +
    geom_line() + geom_point() + sin_lineas
#+end_src
#+caption: Histórico de la proporción de peliculas que pasan la prueba de Bechdel por año. 
#+RESULTS:
[[file:../images/peliculas_historico.jpeg]]

#+REVEAL: split
#+HEADER: :width 700 :height 300 :R-dev-args bg="transparent"
#+begin_src R :file images/peliculas_secuencial.jpeg :exports results :results output graphics file
  ## Analisis secuencial ------------------------------
  library(ggridges)

  tibble(period = "previa", FAIL = 0, PASS = 0) |>
    rbind(bechdel |>
          mutate(period = cut(year, breaks = 5)) |>
          group_by(period) |>
          sample_frac(.3) |>
          ungroup() |>
          group_by(period, binary) |>
          tally() |>
          ungroup() |>
          pivot_wider(values_from = n,
                      names_from = binary,
                      values_fill = 0)) |>
    summarise(period = fct_inorder(period),
              pass = cumsum(PASS),
              fail = cumsum(FAIL),
              rate = pass/(pass + fail),
              alpha = 5 + pass,
              beta  = 11 + fail) |>
    nest(params = c(alpha, beta)) |>
    mutate(muestras = map(params, modelo_beta)) |>
    unnest(muestras, params) |>
    ggplot(aes(muestras, period)) +
    geom_density_ridges(stat = "binline", bins = 40) +
    geom_point(aes(x = pass/(pass + fail), y = period), fill = 'lightblue', shape = 23, size = 5) +
    ## geom_point(aes(x = alpha/(alpha + beta), y = period), fill = 'red', shape = 23, size = 5) + 
    xlim(0,1) + xlab("Tasa de éxito") + sin_lineas
#+end_src
#+caption: La posterior de hoy puede ser la previa de mañana. 
#+RESULTS:
[[file:../images/peliculas_secuencial.jpeg]]

** Tarea

Echenle un ojo a la sección 5.2 de [[https://www.bayesrulesbook.com/][Bayes rules!]] donde se expone a detalle un modelo más del análisis conjugado. ¿Puedes identificar/derivar la distribución predictiva?


* Motivación

Por medio de metodología Bayesiana podemos cuantificar incertidumbre en:
#+ATTR_REVEAL: :frag (appear)
- Observaciones. 
- Parámetros. 
- Estructura. 

#+REVEAL: split
  Es fácil especificar y ajustar modelos. Pero hay preguntas cuyas respuestas no han quedado claras:
#+ATTR_REVEAL: :frag (appear)
  1. Construcción. 
  2. Evaluación. 
  3. Uso.

  #+BEGIN_NOTES
  Programación probabilística. 
  #+END_NOTES


#+REVEAL: split
Los aspectos del flujo de trabajo Bayesiano consideran (citep:Gelman2020):
#+ATTR_REVEAL: :frag (appear)
1. Construcción iterativa de modelos. 
2. Validación de modelo (computacional).
3. Entendimiento de modelo. 
4. Evaluación de modelo.   

** Distinción importante

~Inferencia~ no es lo mismo que ~análisis de datos~ o que un ~flujo de trabajo~. 

#+BEGIN_NOTES

Inferencia (en el contexto bayesiano) es formular y calcular con probabilidades
condicionales.

#+END_NOTES

** ¿Por qué necesitamos un flujo de trabajo?

#+ATTR_REVEAL: :frag (appear)
- El cómputo puede ser complejo.
- Expandir nuestro entendimiento en aplicaciones.
- Entender la relación entre modelos.
- Distintos modelos pueden llegar a distintas conclusiones.

** Proceso iterativo

- La gente de ML sabe que el proceso de construcción de un modelo es iterativo, ¿por qué no utilizarlo?

#+BEGIN_NOTES

Una posible explicación puede encontrarse en citep:Gelman2021. El argumento es formal en cuanto a actualizar nuestras creencias como bayesianos. Sin embargo, con cuidado y un procedimiento científico puede resolver el asunto. 

#+END_NOTES


#+DOWNLOADED: screenshot @ 2022-01-21 23:09:51
#+caption: Tomado de citep:Gelman2020.
#+attr_html: :width 800 :align center
[[file:../images/20220121-230951_screenshot.png]]                                  

bibliographystyle:abbrvnat 
bibliography:references.bib


